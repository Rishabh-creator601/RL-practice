{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rl-set2-kerasrl-pendulum.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdeJxoQxhe-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b2dd63-8474-42fc-fab2-312fca704cdf"
      },
      "source": [
        "!pip install keras-rl2"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-rl2 in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-rl2) (2.7.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.7.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (12.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.42.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.19.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.37.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.17.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.10.0.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.13.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.22.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras-rl2) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-rl2) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-rl2) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-rl2) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-rl2) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-rl2) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-rl2) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->keras-rl2) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->keras-rl2) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->keras-rl2) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->keras-rl2) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow->keras-rl2) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->keras-rl2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->keras-rl2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->keras-rl2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->keras-rl2) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->keras-rl2) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKht8ObjirIL"
      },
      "source": [
        "import gym \n",
        "import os \n",
        "from tensorflow.keras.models import Sequential , Model\n",
        "from tensorflow.keras.layers import Dense,Flatten,Input,Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from rl.agents import DDPGAgent\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.policy import BoltzmannQPolicy\n",
        "import numpy as np\n",
        "from rl.random import OrnsteinUhlenbeckProcess"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B6cvYJWjPwS"
      },
      "source": [
        "env = gym.make('Pendulum-v0')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJfLtvnTjTPY"
      },
      "source": [
        "states  = env.observation_space.shape \n",
        "actions = env.action_space.shape[0]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLwCKIQsjdut",
        "outputId": "fbad08a2-a8b0-4837-a38e-ff049edde76d"
      },
      "source": [
        "states,actions"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3,), 1)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgMX8qiFjfc_"
      },
      "source": [
        "def get_actor_model(states,actions):\n",
        "  model = Sequential([\n",
        "                      Flatten(input_shape=((1,)+states)),\n",
        "                      Dense(128,activation='relu'),\n",
        "                      Dense(64,activation='relu'),\n",
        "                      Dense(32,activation='relu'),\n",
        "                      Dense(actions,activation='linear')\n",
        "  ])\n",
        "  return model "
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAe10FiPkMkI"
      },
      "source": [
        "def get_critic(states,actions):\n",
        "  action_input = Input(shape=(actions,),name='action_input')\n",
        "  obs_input = Input(shape=(1,)+states,name='obs_input')\n",
        "  flattened_input = Flatten()(obs_input)\n",
        "  model = Concatenate()([action_input,flattened_input])\n",
        "  model=Dense(128,activation='relu')(model)\n",
        "  model=Dense(64,activation='relu')(model)\n",
        "  model=Dense(32,activation='relu')(model)\n",
        "  model=Dense(1,activation='linear')(model)\n",
        "  model = Model(inputs=[action_input,obs_input],outputs=model)\n",
        "  return model,action_input\n",
        "  \n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bda5jKiEn6dr"
      },
      "source": [
        "def build_agent(critic,actor,states,actions,action_input):\n",
        "  memory = SequentialMemory(limit=10000,window_length=1)\n",
        "  policy = BoltzmannQPolicy()\n",
        "  random_process = OrnsteinUhlenbeckProcess(size=actions,theta=.15,mu=0,sigma=.3)\n",
        "  agent = DDPGAgent(memory=memory,critic=critic,actor=actor,critic_action_input=action_input,nb_actions=actions,random_process=random_process,nb_steps_warmup_actor=100,nb_steps_warmup_critic=100,gamma=.99,target_model_update=1e-3)\n",
        "  agent.compile(Adam(learning_rate=1e-2),metrics=['mae'])\n",
        "  return agent "
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlecayWEMD6n"
      },
      "source": [
        "actor = get_actor_model(states,actions)\n",
        "critic,action_input = get_critic(states,actions)\n",
        "ddpg = build_agent(critic,actor,states,actions,action_input)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABIFX9ckMYUC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1889ea29-13b6-4213-f8fd-e947083aeffb"
      },
      "source": [
        "ddpg.fit(env,nb_steps=50000,visualize=False)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 50000 steps ...\n",
            "Interval 1 (0 steps performed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000/10000 [==============================] - 119s 12ms/step - reward: -6.8126\n",
            "50 episodes - episode_reward: -1362.525 [-1796.054, -414.676] - loss: 2.999 - mae: 0.869 - mean_q: -33.594\n",
            "\n",
            "Interval 2 (10000 steps performed)\n",
            "10000/10000 [==============================] - 121s 12ms/step - reward: -3.8495\n",
            "50 episodes - episode_reward: -769.899 [-1495.627, -125.603] - loss: 12.145 - mae: 2.009 - mean_q: -61.612\n",
            "\n",
            "Interval 3 (20000 steps performed)\n",
            "10000/10000 [==============================] - 120s 12ms/step - reward: -1.6024\n",
            "50 episodes - episode_reward: -320.484 [-1492.794, -7.693] - loss: 7.616 - mae: 1.444 - mean_q: -34.928\n",
            "\n",
            "Interval 4 (30000 steps performed)\n",
            "10000/10000 [==============================] - 121s 12ms/step - reward: -1.0204\n",
            "50 episodes - episode_reward: -204.080 [-900.712, -2.221] - loss: 6.971 - mae: 1.258 - mean_q: -23.463\n",
            "\n",
            "Interval 5 (40000 steps performed)\n",
            "10000/10000 [==============================] - 119s 12ms/step - reward: -1.5587\n",
            "done, took 599.444 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff54c20cb10>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZjWpOTbU-_S",
        "outputId": "5bdeb061-eff7-4415-fd27-a1ed6481121a"
      },
      "source": [
        "scores = ddpg.test(env,nb_episodes=100,visualize=False)\n",
        "print('AVERAGE REWARD :',np.mean(scores.history['episode_reward']))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 100 episodes ...\n",
            "Episode 1: reward: -222.922, steps: 200\n",
            "Episode 2: reward: -120.915, steps: 200\n",
            "Episode 3: reward: -119.192, steps: 200\n",
            "Episode 4: reward: -1.394, steps: 200\n",
            "Episode 5: reward: -225.195, steps: 200\n",
            "Episode 6: reward: -123.057, steps: 200\n",
            "Episode 7: reward: -0.444, steps: 200\n",
            "Episode 8: reward: -376.883, steps: 200\n",
            "Episode 9: reward: -2.027, steps: 200\n",
            "Episode 10: reward: -118.522, steps: 200\n",
            "Episode 11: reward: -116.116, steps: 200\n",
            "Episode 12: reward: -120.466, steps: 200\n",
            "Episode 13: reward: -670.302, steps: 200\n",
            "Episode 14: reward: -232.010, steps: 200\n",
            "Episode 15: reward: -233.511, steps: 200\n",
            "Episode 16: reward: -509.926, steps: 200\n",
            "Episode 17: reward: -229.213, steps: 200\n",
            "Episode 18: reward: -114.990, steps: 200\n",
            "Episode 19: reward: -122.684, steps: 200\n",
            "Episode 20: reward: -313.143, steps: 200\n",
            "Episode 21: reward: -0.649, steps: 200\n",
            "Episode 22: reward: -243.924, steps: 200\n",
            "Episode 23: reward: -383.734, steps: 200\n",
            "Episode 24: reward: -1.388, steps: 200\n",
            "Episode 25: reward: -369.850, steps: 200\n",
            "Episode 26: reward: -119.357, steps: 200\n",
            "Episode 27: reward: -249.698, steps: 200\n",
            "Episode 28: reward: -1.058, steps: 200\n",
            "Episode 29: reward: -119.954, steps: 200\n",
            "Episode 30: reward: -227.242, steps: 200\n",
            "Episode 31: reward: -240.546, steps: 200\n",
            "Episode 32: reward: -130.830, steps: 200\n",
            "Episode 33: reward: -378.449, steps: 200\n",
            "Episode 34: reward: -647.075, steps: 200\n",
            "Episode 35: reward: -1.526, steps: 200\n",
            "Episode 36: reward: -468.625, steps: 200\n",
            "Episode 37: reward: -228.659, steps: 200\n",
            "Episode 38: reward: -368.033, steps: 200\n",
            "Episode 39: reward: -116.234, steps: 200\n",
            "Episode 40: reward: -2.346, steps: 200\n",
            "Episode 41: reward: -232.995, steps: 200\n",
            "Episode 42: reward: -254.048, steps: 200\n",
            "Episode 43: reward: -0.875, steps: 200\n",
            "Episode 44: reward: -116.960, steps: 200\n",
            "Episode 45: reward: -368.988, steps: 200\n",
            "Episode 46: reward: -510.336, steps: 200\n",
            "Episode 47: reward: -117.083, steps: 200\n",
            "Episode 48: reward: -119.351, steps: 200\n",
            "Episode 49: reward: -315.462, steps: 200\n",
            "Episode 50: reward: -373.146, steps: 200\n",
            "Episode 51: reward: -235.269, steps: 200\n",
            "Episode 52: reward: -126.944, steps: 200\n",
            "Episode 53: reward: -115.192, steps: 200\n",
            "Episode 54: reward: -120.124, steps: 200\n",
            "Episode 55: reward: -234.878, steps: 200\n",
            "Episode 56: reward: -247.490, steps: 200\n",
            "Episode 57: reward: -0.710, steps: 200\n",
            "Episode 58: reward: -118.353, steps: 200\n",
            "Episode 59: reward: -116.522, steps: 200\n",
            "Episode 60: reward: -222.051, steps: 200\n",
            "Episode 61: reward: -2.111, steps: 200\n",
            "Episode 62: reward: -118.728, steps: 200\n",
            "Episode 63: reward: -0.976, steps: 200\n",
            "Episode 64: reward: -233.007, steps: 200\n",
            "Episode 65: reward: -309.258, steps: 200\n",
            "Episode 66: reward: -125.710, steps: 200\n",
            "Episode 67: reward: -116.389, steps: 200\n",
            "Episode 68: reward: -232.603, steps: 200\n",
            "Episode 69: reward: -789.533, steps: 200\n",
            "Episode 70: reward: -122.236, steps: 200\n",
            "Episode 71: reward: -118.674, steps: 200\n",
            "Episode 72: reward: -1.974, steps: 200\n",
            "Episode 73: reward: -122.934, steps: 200\n",
            "Episode 74: reward: -232.709, steps: 200\n",
            "Episode 75: reward: -244.809, steps: 200\n",
            "Episode 76: reward: -230.522, steps: 200\n",
            "Episode 77: reward: -364.778, steps: 200\n",
            "Episode 78: reward: -116.186, steps: 200\n",
            "Episode 79: reward: -256.154, steps: 200\n",
            "Episode 80: reward: -220.787, steps: 200\n",
            "Episode 81: reward: -116.255, steps: 200\n",
            "Episode 82: reward: -116.535, steps: 200\n",
            "Episode 83: reward: -119.872, steps: 200\n",
            "Episode 84: reward: -119.038, steps: 200\n",
            "Episode 85: reward: -124.321, steps: 200\n",
            "Episode 86: reward: -367.894, steps: 200\n",
            "Episode 87: reward: -117.952, steps: 200\n",
            "Episode 88: reward: -241.481, steps: 200\n",
            "Episode 89: reward: -128.941, steps: 200\n",
            "Episode 90: reward: -126.455, steps: 200\n",
            "Episode 91: reward: -121.169, steps: 200\n",
            "Episode 92: reward: -1.022, steps: 200\n",
            "Episode 93: reward: -386.918, steps: 200\n",
            "Episode 94: reward: -118.458, steps: 200\n",
            "Episode 95: reward: -772.661, steps: 200\n",
            "Episode 96: reward: -237.298, steps: 200\n",
            "Episode 97: reward: -114.480, steps: 200\n",
            "Episode 98: reward: -223.613, steps: 200\n",
            "Episode 99: reward: -241.312, steps: 200\n",
            "Episode 100: reward: -122.604, steps: 200\n",
            "AVERAGE REWARD : -200.97222197581002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgwfk1qTTtC_"
      },
      "source": [
        "os.mkdir('Models')\n",
        "model_path = os.path.join('Models','DDPG_PENDULUM_KERASRL.h5f')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytPfrWTlqMpu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFg75pvSUFO8"
      },
      "source": [
        "ddpg.save_weights(model_path)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMhKObcKYREU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}